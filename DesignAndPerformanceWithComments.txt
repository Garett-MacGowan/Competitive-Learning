Author: Garett MacGowan 
Student Number: 10197107 

Required Libraries 
Numpy -> pip install numpy 
sklearn -> pip install scikit-learn 
matplotlib -> pip install matplotlib

*** Design ***
Assumptions:
Whenever there is a tie for the ownership of a point by a cluster,
the tie is always broken randomly, rather than skipping the point.
General:
The clustering.py file implements both a simple competitive clustering
algorithm and k-means clustering. Both approaches use dot product as
a metric for similarity. For this to work properly, the data is adjusted
to be centered about the mean. Before the final results are shown, the means
for each attribute are re-added.
A learning rate is used for the simple competitive clustering version so that
the centroids can approach a stable state.
Both algorithms implement early stopping behaviour. The simple competitive
clustering version stops when the centroids stop moving and the K-means clustering
version stops when the clustering error stops decreasing.

*** Analysis ***
Both algorithms seem to produce approximately the same results on this dataset,
though they are unable to split the dataset into the two complex clusters that
are present. K-means is a much faster approach for very similar clustering
performance. 

Initial centroids are the same for both networks 
Initial centroids (each column is a centroid): 
[[-0.00357525  0.52766022]
 [ 0.33780932  0.5291569 ]
 [ 1.33940645  1.0926736 ]]

*** Simple Competitive Clustering *** 
Final centroids (each column is a centroid): 
[[-0.19891304  1.20057255]
 [ 0.57631773 -0.09559856]
 [ 0.57005354  0.40304264]]
Cluster errors for each cluster 
[1.12752384 1.30343688]
Total error: 
2.4309607269878706

*** K-Means Clustering *** 
Final centroids (each column is a centroid): 
[[-0.19535914  1.21376914]
 [ 0.57841385 -0.08468027]
 [ 0.5817694   0.41533018]]
Cluster errors for each cluster 
[1.12083723 1.3138701 ]
Total error: 
2.434707327148899

